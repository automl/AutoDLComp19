{
  # Codalab submission
  include: {
    packages: { # Packages and files listed here are always assumed to lie in the
                # currently used site-packages folder. If an entry is a folder
                # the whole folder gets added to the zip
      apex: [
        apex
        apex-0.1-py3.5.egg-info
        amp_C.cpython-35m-x86_64-linux-gnu.so
        apex_C.cpython-35m-x86_64-linux-gnu.so
        fused_adam_cuda.cpython-35m-x86_64-linux-gnu.so
        fused_layer_norm_cuda.cpython-35m-x86_64-linux-gnu.so
        syncbn.cpython-35m-x86_64-linux-gnu.so
      ]
    },
    pretrained_weights: [ # List the pretrained weight you want packsubmission.py to include
      # BnT_Video_input_128.pth.tar
      Averagenet_RGB_Kinetics_128.pth.tar
      resnet18-5c106cde.pth
    ]
  },

  # Automatic mixed precision ops from the apex module
  use_amp: false,
  amp_args: { # See https://nvidia.github.io/apex/amp.html#opt-levels
    opt_level: "O2" # O0 is normal learning and apex does nothing
    keep_batchnorm_fp32: true,
    loss_scale: "dynamic"
  },

  # General
  log_level: 'DEBUG',
  earlystop: 300, # How many seconds shall we ingest
  check_for_shuffling: false,
  benchmark_transformations: false,
  benchmark_time_till_first_prediction: false,


  # CUDNN
  cudnn_benchmark: true,
  cudnn_deterministic: false # negatively affects performance, only use for testing

  # SEEDS
  tf_seed: 42,
  np_random_seed: 42,
  torch_manual_seed: 42,
  torch_cuda_manual_seed_all: 42,

  # Trainer args
  trainer_args: {
    validation_buffer: 0, # The intent is to seamlessly collect batches
                          # during training in a buffer for later use
                          # and skip them if seen again
    t_diff: 0,
  },

  tester_args: {
    entropy_splits: 0,
  }

###############################################################################
# Beyond this point come specialized configurations
###############################################################################
  selection: { # This will be passed on not expanded
    image: {
      max_size: 128, # maximum resolution to resize the input images/frames
      base: 16, # in case the H != W scale them as multiple of 16
      freeze_portion: 0.0, # freezes a image network's first percent of layers
      dropout: 0.3,
      optimizer: 'SGD',
      optim_args: {
        lr: 0.025,
        weight_decay: 0.001,
        momentum: 0.9,
      }
    },
    video: {
      segment_coeff: 10, # num_segemts = frame_count / segment_coeff
      freeze_portion: 0.64, # freezes a video network's first percent of layers
      modality: 'RGB',
      dropout: 0.1, # on average net this only controls alphadrop sitting on the outputlayer
      optimizer: 'Adam',
      optim_args: {
        lr: 0.001,
      }
      transformations: 'gpu_resize', # Name of the function in transformations.video
                                     # augmenting the model and returning transformations
                                     # for the datasets to use
      # If the chosen function needs additional agruments, specify them here
      transformation_args: {
        use_gpu_resize: 'True',
        resize_factor: 1.2,
        flip_factor: 0.4
      },
      policy_args: { # This will be passed on expanded
        t_diff: 0.01,
      },
      train_loader_args: {
        batch_size: 32, # Will be automatically adjusted if too big
        pin_memory: true,
      }
      test_loader_args: {
        batch_size: 128, # Will be automatically adjusted if too big
        pin_memory: true,
      }
    }
  }
}
